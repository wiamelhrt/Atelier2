{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3cec0f99",
      "metadata": {
        "id": "3cec0f99"
      },
      "source": [
        "# Image classification with modern MLP models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80d2db86",
      "metadata": {
        "id": "80d2db86"
      },
      "source": [
        "### This example implements three modern attention-free, multi-layer perceptron (MLP) based models for image classification, demonstrated on the CIFAR-100 dataset:\n",
        "    The MLP-Mixer model, by Ilya Tolstikhin et al., based on two types of MLPs.\n",
        "    The FNet model, by James Lee-Thorp et al., based on unparameterized Fourier Transform.\n",
        "    The gMLP model, by Hanxiao Liu et al., based on MLP with gating.\n",
        "The purpose of the example is not to compare between these models, as they might perform differently on different datasets with well-tuned hyperparameters. Rather, it is to show simple implementations of their main building blocks. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d4d01dbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4d01dbc",
        "outputId": "883d7057-28da-41a1-e8f2-2b4106513023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n"
          ]
        }
      ],
      "source": [
        "pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b4dffa4",
      "metadata": {
        "id": "0b4dffa4"
      },
      "source": [
        "## Setup "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAqJoiIZVnSP",
        "outputId": "bf37fbc3-a7f8-44b9-8f06-628965f0c4d1"
      },
      "id": "rAqJoiIZVnSP",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7d89d41",
      "metadata": {
        "id": "a7d89d41"
      },
      "source": [
        "### Import all libraries that we need "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6d020e81",
      "metadata": {
        "id": "6d020e81"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2944d499",
      "metadata": {
        "id": "2944d499"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9e5c7a26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e5c7a26",
        "outputId": "36df9538-c1e4-417a-b50e-b4d930fc2093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 100\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4252cce",
      "metadata": {
        "id": "a4252cce"
      },
      "source": [
        "## Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ac5aa301",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac5aa301",
        "outputId": "7b3077d6-2eae-4b5a-effd-1661102b1582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: 64 X 64 = 4096\n",
            "Patch size: 8 X 8 = 64 \n",
            "Patches per image: 64\n",
            "Elements per patch (3 channels): 192\n"
          ]
        }
      ],
      "source": [
        "weight_decay = 0.0001\n",
        "batch_size = 128\n",
        "num_epochs = 50\n",
        "dropout_rate = 0.2\n",
        "image_size = 64  # We'll resize input images to this size.\n",
        "patch_size = 8  # Size of the patches to be extracted from the input images.\n",
        "num_patches = (image_size // patch_size) ** 2  # Size of the data array.\n",
        "embedding_dim = 256  # Number of hidden units.\n",
        "num_blocks = 4  # Number of blocks.\n",
        "\n",
        "print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n",
        "print(f\"Patches per image: {num_patches}\")\n",
        "print(f\"Elements per patch (3 channels): {(patch_size ** 2) * 3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06bf5e46",
      "metadata": {
        "id": "06bf5e46"
      },
      "source": [
        "## Build a classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9a0a8f1",
      "metadata": {
        "id": "c9a0a8f1"
      },
      "source": [
        "### implement a method that builds a classifier given the processing blocks.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d4372b41",
      "metadata": {
        "id": "d4372b41"
      },
      "outputs": [],
      "source": [
        "def build_classifier(blocks, positional_encoding=False):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size, num_patches)(augmented)\n",
        "    # Encode patches to generate a [batch_size, num_patches, embedding_dim] tensor.\n",
        "    x = layers.Dense(units=embedding_dim)(patches)\n",
        "    if positional_encoding:\n",
        "        positions = tf.range(start=0, limit=num_patches, delta=1)\n",
        "        position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=embedding_dim\n",
        "        )(positions)\n",
        "        x = x + position_embedding\n",
        "    # Process x using the module blocks.\n",
        "    x = blocks(x)\n",
        "    # Apply global average pooling to generate a [batch_size, embedding_dim] representation tensor.\n",
        "    representation = layers.GlobalAveragePooling1D()(x)\n",
        "    # Apply dropout.\n",
        "    representation = layers.Dropout(rate=dropout_rate)(representation)\n",
        "    # Compute logits outputs.\n",
        "    logits = layers.Dense(num_classes)(representation)\n",
        "    # Create the Keras model.\n",
        "    return keras.Model(inputs=inputs, outputs=logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba6a22dc",
      "metadata": {
        "id": "ba6a22dc"
      },
      "source": [
        "## Define an experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae9e04c8",
      "metadata": {
        "id": "ae9e04c8"
      },
      "source": [
        "### implement a utility function to compile, train, and evaluate a given model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a83e349c",
      "metadata": {
        "id": "a83e349c"
      },
      "outputs": [],
      "source": [
        "def run_experiment(model):\n",
        "    # Create Adam optimizer with weight decay.\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay,\n",
        "    )\n",
        "    # Compile the model.\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top5-acc\"),\n",
        "        ],\n",
        "    )\n",
        "    # Create a learning rate scheduler callback.\n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=5\n",
        "    )\n",
        "    # Create an early stopping callback.\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
        "    )\n",
        "    # Fit the model.\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "    )\n",
        "\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    # Return history to plot learning curves.\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14a727f7",
      "metadata": {
        "id": "14a727f7"
      },
      "source": [
        "## Use data augementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "41ee9e0c",
      "metadata": {
        "id": "41ee9e0c"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        ),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd77ce2d",
      "metadata": {
        "id": "cd77ce2d"
      },
      "source": [
        "## Implement patch extraction as a layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "12564181",
      "metadata": {
        "id": "12564181"
      },
      "outputs": [],
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size, num_patches):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = num_patches\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, self.num_patches, patch_dims])\n",
        "        return patches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "245f6385",
      "metadata": {
        "id": "245f6385"
      },
      "source": [
        "## The MLP-Mixer model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e89ba22b",
      "metadata": {
        "id": "e89ba22b"
      },
      "source": [
        "### Implement the MLP-Mixer module "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The MLP-Mixer is an architecture based exclusively on multi-layer perceptrons (MLPs), that contains two types of MLP layers:\n",
        "\n",
        "  One applied independently to image patches, which mixes the per-location features.\n",
        "  \n",
        "  The other applied across patches (along channels), which mixes spatial information. "
      ],
      "metadata": {
        "id": "B-_Wf4lTbAfb"
      },
      "id": "B-_Wf4lTbAfb"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a35c811b",
      "metadata": {
        "id": "a35c811b"
      },
      "outputs": [],
      "source": [
        "class MLPMixerLayer(layers.Layer):\n",
        "    def __init__(self, num_patches, hidden_units, dropout_rate, *args, **kwargs):\n",
        "        super(MLPMixerLayer, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.mlp1 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=num_patches),\n",
        "                tfa.layers.GELU(),\n",
        "                layers.Dense(units=num_patches),\n",
        "                layers.Dropout(rate=dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "        self.mlp2 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=num_patches),\n",
        "                tfa.layers.GELU(),\n",
        "                layers.Dense(units=embedding_dim),\n",
        "                layers.Dropout(rate=dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "        self.normalize = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply layer normalization.\n",
        "        x = self.normalize(inputs)\n",
        "        # Transpose inputs from [num_batches, num_patches, hidden_units] to [num_batches, hidden_units, num_patches].\n",
        "        x_channels = tf.linalg.matrix_transpose(x)\n",
        "        # Apply mlp1 on each channel independently.\n",
        "        mlp1_outputs = self.mlp1(x_channels)\n",
        "        # Transpose mlp1_outputs from [num_batches, hidden_dim, num_patches] to [num_batches, num_patches, hidden_units].\n",
        "        mlp1_outputs = tf.linalg.matrix_transpose(mlp1_outputs)\n",
        "        # Add skip connection.\n",
        "        x = mlp1_outputs + inputs\n",
        "        # Apply layer normalization.\n",
        "        x_patches = self.normalize(x)\n",
        "        # Apply mlp2 on each patch independtenly.\n",
        "        mlp2_outputs = self.mlp2(x_patches)\n",
        "        # Add skip connection.\n",
        "        x = x + mlp2_outputs\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cf9be0e",
      "metadata": {
        "id": "5cf9be0e"
      },
      "source": [
        "### Build, train, and evaluate the MLP-Mixer model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a067d01d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a067d01d",
        "outputId": "bcaabae0-d4c0-4c3a-e937-5520d23d88f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "352/352 [==============================] - 50s 113ms/step - loss: 3.8753 - acc: 0.1106 - top5-acc: 0.3162 - val_loss: 3.5713 - val_acc: 0.1764 - val_top5-acc: 0.4222 - lr: 0.0050\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 39s 111ms/step - loss: 3.3633 - acc: 0.1896 - top5-acc: 0.4644 - val_loss: 3.2103 - val_acc: 0.2394 - val_top5-acc: 0.5170 - lr: 0.0050\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 39s 110ms/step - loss: 3.1404 - acc: 0.2321 - top5-acc: 0.5258 - val_loss: 3.0634 - val_acc: 0.2638 - val_top5-acc: 0.5548 - lr: 0.0050\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.9857 - acc: 0.2628 - top5-acc: 0.5645 - val_loss: 2.9254 - val_acc: 0.2772 - val_top5-acc: 0.5884 - lr: 0.0050\n",
            "Epoch 5/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.8911 - acc: 0.2826 - top5-acc: 0.5848 - val_loss: 2.8329 - val_acc: 0.2932 - val_top5-acc: 0.6182 - lr: 0.0050\n",
            "Epoch 6/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.7898 - acc: 0.2995 - top5-acc: 0.6113 - val_loss: 2.7124 - val_acc: 0.3204 - val_top5-acc: 0.6318 - lr: 0.0050\n",
            "Epoch 7/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.7226 - acc: 0.3101 - top5-acc: 0.6242 - val_loss: 2.6893 - val_acc: 0.3336 - val_top5-acc: 0.6438 - lr: 0.0050\n",
            "Epoch 8/50\n",
            "352/352 [==============================] - 37s 106ms/step - loss: 2.6791 - acc: 0.3199 - top5-acc: 0.6357 - val_loss: 2.7104 - val_acc: 0.3278 - val_top5-acc: 0.6386 - lr: 0.0050\n",
            "Epoch 9/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.6336 - acc: 0.3314 - top5-acc: 0.6467 - val_loss: 2.6888 - val_acc: 0.3418 - val_top5-acc: 0.6430 - lr: 0.0050\n",
            "Epoch 10/50\n",
            "352/352 [==============================] - 38s 109ms/step - loss: 2.5802 - acc: 0.3423 - top5-acc: 0.6588 - val_loss: 2.6146 - val_acc: 0.3534 - val_top5-acc: 0.6640 - lr: 0.0050\n",
            "Epoch 11/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.5627 - acc: 0.3460 - top5-acc: 0.6621 - val_loss: 2.5599 - val_acc: 0.3630 - val_top5-acc: 0.6690 - lr: 0.0050\n",
            "Epoch 12/50\n",
            "352/352 [==============================] - 37s 106ms/step - loss: 2.5214 - acc: 0.3533 - top5-acc: 0.6674 - val_loss: 2.5648 - val_acc: 0.3538 - val_top5-acc: 0.6776 - lr: 0.0050\n",
            "Epoch 13/50\n",
            "352/352 [==============================] - 37s 107ms/step - loss: 2.4958 - acc: 0.3567 - top5-acc: 0.6779 - val_loss: 2.4726 - val_acc: 0.3752 - val_top5-acc: 0.6856 - lr: 0.0050\n",
            "Epoch 14/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.4664 - acc: 0.3662 - top5-acc: 0.6832 - val_loss: 2.5519 - val_acc: 0.3632 - val_top5-acc: 0.6762 - lr: 0.0050\n",
            "Epoch 15/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.4306 - acc: 0.3718 - top5-acc: 0.6892 - val_loss: 2.4967 - val_acc: 0.3770 - val_top5-acc: 0.6906 - lr: 0.0050\n",
            "Epoch 16/50\n",
            "352/352 [==============================] - 37s 106ms/step - loss: 2.4110 - acc: 0.3738 - top5-acc: 0.6962 - val_loss: 2.5620 - val_acc: 0.3616 - val_top5-acc: 0.6758 - lr: 0.0050\n",
            "Epoch 17/50\n",
            "352/352 [==============================] - 38s 109ms/step - loss: 2.3895 - acc: 0.3816 - top5-acc: 0.6999 - val_loss: 2.5214 - val_acc: 0.3774 - val_top5-acc: 0.6902 - lr: 0.0050\n",
            "Epoch 18/50\n",
            "352/352 [==============================] - 43s 123ms/step - loss: 2.3646 - acc: 0.3860 - top5-acc: 0.7038 - val_loss: 2.4731 - val_acc: 0.3774 - val_top5-acc: 0.6998 - lr: 0.0050\n",
            "Epoch 19/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.1411 - acc: 0.4332 - top5-acc: 0.7464 - val_loss: 2.2567 - val_acc: 0.4260 - val_top5-acc: 0.7396 - lr: 0.0025\n",
            "Epoch 20/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.0828 - acc: 0.4479 - top5-acc: 0.7577 - val_loss: 2.2227 - val_acc: 0.4302 - val_top5-acc: 0.7408 - lr: 0.0025\n",
            "Epoch 21/50\n",
            "352/352 [==============================] - 37s 106ms/step - loss: 2.0641 - acc: 0.4472 - top5-acc: 0.7627 - val_loss: 2.2477 - val_acc: 0.4356 - val_top5-acc: 0.7402 - lr: 0.0025\n",
            "Epoch 22/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.0476 - acc: 0.4524 - top5-acc: 0.7628 - val_loss: 2.1983 - val_acc: 0.4364 - val_top5-acc: 0.7418 - lr: 0.0025\n",
            "Epoch 23/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.0315 - acc: 0.4563 - top5-acc: 0.7676 - val_loss: 2.2388 - val_acc: 0.4350 - val_top5-acc: 0.7446 - lr: 0.0025\n",
            "Epoch 24/50\n",
            "352/352 [==============================] - 38s 109ms/step - loss: 2.0114 - acc: 0.4593 - top5-acc: 0.7736 - val_loss: 2.1659 - val_acc: 0.4432 - val_top5-acc: 0.7532 - lr: 0.0025\n",
            "Epoch 25/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.9932 - acc: 0.4626 - top5-acc: 0.7755 - val_loss: 2.1664 - val_acc: 0.4382 - val_top5-acc: 0.7544 - lr: 0.0025\n",
            "Epoch 26/50\n",
            "352/352 [==============================] - 39s 110ms/step - loss: 1.9849 - acc: 0.4648 - top5-acc: 0.7790 - val_loss: 2.2293 - val_acc: 0.4386 - val_top5-acc: 0.7506 - lr: 0.0025\n",
            "Epoch 27/50\n",
            "352/352 [==============================] - 41s 117ms/step - loss: 1.9651 - acc: 0.4711 - top5-acc: 0.7816 - val_loss: 2.1818 - val_acc: 0.4404 - val_top5-acc: 0.7468 - lr: 0.0025\n",
            "Epoch 28/50\n",
            "352/352 [==============================] - 38s 109ms/step - loss: 1.9473 - acc: 0.4742 - top5-acc: 0.7861 - val_loss: 2.1522 - val_acc: 0.4524 - val_top5-acc: 0.7594 - lr: 0.0025\n",
            "Epoch 29/50\n",
            "352/352 [==============================] - 37s 106ms/step - loss: 1.9391 - acc: 0.4748 - top5-acc: 0.7858 - val_loss: 2.1291 - val_acc: 0.4538 - val_top5-acc: 0.7642 - lr: 0.0025\n",
            "Epoch 30/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.9294 - acc: 0.4785 - top5-acc: 0.7865 - val_loss: 2.1012 - val_acc: 0.4574 - val_top5-acc: 0.7618 - lr: 0.0025\n",
            "Epoch 31/50\n",
            "352/352 [==============================] - 43s 122ms/step - loss: 1.9141 - acc: 0.4841 - top5-acc: 0.7909 - val_loss: 2.0935 - val_acc: 0.4634 - val_top5-acc: 0.7652 - lr: 0.0025\n",
            "Epoch 32/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.8979 - acc: 0.4860 - top5-acc: 0.7954 - val_loss: 2.1198 - val_acc: 0.4576 - val_top5-acc: 0.7628 - lr: 0.0025\n",
            "Epoch 33/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.8944 - acc: 0.4856 - top5-acc: 0.7962 - val_loss: 2.1361 - val_acc: 0.4532 - val_top5-acc: 0.7670 - lr: 0.0025\n",
            "Epoch 34/50\n",
            "352/352 [==============================] - 40s 114ms/step - loss: 1.8965 - acc: 0.4829 - top5-acc: 0.7952 - val_loss: 2.0910 - val_acc: 0.4550 - val_top5-acc: 0.7742 - lr: 0.0025\n",
            "Epoch 35/50\n",
            "352/352 [==============================] - 41s 115ms/step - loss: 1.8876 - acc: 0.4853 - top5-acc: 0.7965 - val_loss: 2.0983 - val_acc: 0.4554 - val_top5-acc: 0.7694 - lr: 0.0025\n",
            "Epoch 36/50\n",
            "352/352 [==============================] - 40s 113ms/step - loss: 1.8767 - acc: 0.4922 - top5-acc: 0.7993 - val_loss: 2.1355 - val_acc: 0.4506 - val_top5-acc: 0.7600 - lr: 0.0025\n",
            "Epoch 37/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 1.8637 - acc: 0.4930 - top5-acc: 0.8022 - val_loss: 2.0654 - val_acc: 0.4646 - val_top5-acc: 0.7720 - lr: 0.0025\n",
            "Epoch 38/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.8634 - acc: 0.4932 - top5-acc: 0.8012 - val_loss: 2.1217 - val_acc: 0.4552 - val_top5-acc: 0.7660 - lr: 0.0025\n",
            "Epoch 39/50\n",
            "352/352 [==============================] - 37s 105ms/step - loss: 1.8488 - acc: 0.4954 - top5-acc: 0.8049 - val_loss: 2.0872 - val_acc: 0.4684 - val_top5-acc: 0.7670 - lr: 0.0025\n",
            "Epoch 40/50\n",
            "352/352 [==============================] - 37s 106ms/step - loss: 1.8455 - acc: 0.4964 - top5-acc: 0.8044 - val_loss: 2.1421 - val_acc: 0.4544 - val_top5-acc: 0.7618 - lr: 0.0025\n",
            "Epoch 41/50\n",
            "352/352 [==============================] - 37s 105ms/step - loss: 1.8505 - acc: 0.4949 - top5-acc: 0.8029 - val_loss: 2.1075 - val_acc: 0.4562 - val_top5-acc: 0.7710 - lr: 0.0025\n",
            "Epoch 42/50\n",
            "352/352 [==============================] - 37s 106ms/step - loss: 1.8245 - acc: 0.5009 - top5-acc: 0.8080 - val_loss: 2.0702 - val_acc: 0.4754 - val_top5-acc: 0.7690 - lr: 0.0025\n",
            "Epoch 43/50\n",
            "352/352 [==============================] - 37s 107ms/step - loss: 1.6907 - acc: 0.5340 - top5-acc: 0.8307 - val_loss: 1.9798 - val_acc: 0.4854 - val_top5-acc: 0.7820 - lr: 0.0012\n",
            "Epoch 44/50\n",
            "352/352 [==============================] - 39s 109ms/step - loss: 1.6603 - acc: 0.5379 - top5-acc: 0.8376 - val_loss: 2.0187 - val_acc: 0.4872 - val_top5-acc: 0.7870 - lr: 0.0012\n",
            "Epoch 45/50\n",
            "352/352 [==============================] - 37s 106ms/step - loss: 1.6535 - acc: 0.5386 - top5-acc: 0.8377 - val_loss: 1.9793 - val_acc: 0.4844 - val_top5-acc: 0.7878 - lr: 0.0012\n",
            "Epoch 46/50\n",
            "352/352 [==============================] - 41s 118ms/step - loss: 1.6509 - acc: 0.5415 - top5-acc: 0.8383 - val_loss: 2.0007 - val_acc: 0.4754 - val_top5-acc: 0.7850 - lr: 0.0012\n",
            "Epoch 47/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.6482 - acc: 0.5433 - top5-acc: 0.8394 - val_loss: 2.0091 - val_acc: 0.4844 - val_top5-acc: 0.7860 - lr: 0.0012\n",
            "Epoch 48/50\n",
            "352/352 [==============================] - 37s 106ms/step - loss: 1.6527 - acc: 0.5414 - top5-acc: 0.8388 - val_loss: 1.9630 - val_acc: 0.4944 - val_top5-acc: 0.7880 - lr: 0.0012\n",
            "Epoch 49/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.6440 - acc: 0.5417 - top5-acc: 0.8401 - val_loss: 1.9580 - val_acc: 0.4908 - val_top5-acc: 0.7884 - lr: 0.0012\n",
            "Epoch 50/50\n",
            "352/352 [==============================] - 37s 105ms/step - loss: 1.6390 - acc: 0.5432 - top5-acc: 0.8400 - val_loss: 1.9405 - val_acc: 0.4932 - val_top5-acc: 0.7940 - lr: 0.0012\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.8960 - acc: 0.5080 - top5-acc: 0.7935\n",
            "Test accuracy: 50.8%\n",
            "Test top 5 accuracy: 79.35%\n"
          ]
        }
      ],
      "source": [
        "mlpmixer_blocks = keras.Sequential(\n",
        "    [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n",
        ")\n",
        "learning_rate = 0.005\n",
        "mlpmixer_classifier = build_classifier(mlpmixer_blocks)\n",
        "history = run_experiment(mlpmixer_classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bq-YtsAOaWT9"
      },
      "id": "bq-YtsAOaWT9"
    },
    {
      "cell_type": "markdown",
      "id": "998f51eb",
      "metadata": {
        "id": "998f51eb"
      },
      "source": [
        "## The FNet model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2d362b0",
      "metadata": {
        "id": "d2d362b0"
      },
      "source": [
        "### Implement the FNet module "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bbe2635a",
      "metadata": {
        "id": "bbe2635a"
      },
      "outputs": [],
      "source": [
        "class FNetLayer(layers.Layer):\n",
        "    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n",
        "        super(FNetLayer, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=embedding_dim),\n",
        "                tfa.layers.GELU(),\n",
        "                layers.Dropout(rate=dropout_rate),\n",
        "                layers.Dense(units=embedding_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.normalize1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.normalize2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply fourier transformations.\n",
        "        x = tf.cast(\n",
        "            tf.signal.fft2d(tf.cast(inputs, dtype=tf.dtypes.complex64)),\n",
        "            dtype=tf.dtypes.float32,\n",
        "        )\n",
        "        # Add skip connection.\n",
        "        x = x + inputs\n",
        "        # Apply layer normalization.\n",
        "        x = self.normalize1(x)\n",
        "        # Apply Feedfowrad network.\n",
        "        x_ffn = self.ffn(x)\n",
        "        # Add skip connection.\n",
        "        x = x + x_ffn\n",
        "        # Apply layer normalization.\n",
        "        return self.normalize2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The FNet uses a similar block to the Transformer block. However, FNet replaces the self-attention layer in the Transformer block with a parameter-free 2D Fourier transformation layer:\n",
        "\n",
        "  One 1D Fourier Transform is applied along the patches.\n",
        "\n",
        "  One 1D Fourier Transform is applied along the channels."
      ],
      "metadata": {
        "id": "rRMzqb4EbHb4"
      },
      "id": "rRMzqb4EbHb4"
    },
    {
      "cell_type": "markdown",
      "id": "59b55e58",
      "metadata": {
        "id": "59b55e58"
      },
      "source": [
        "### Build, train, and evaluate the FNet model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e1a4c8b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1a4c8b0",
        "outputId": "dd044fdb-1978-4375-a6e4-f46f00f7e26e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "352/352 [==============================] - 43s 109ms/step - loss: 4.1378 - acc: 0.0729 - top5-acc: 0.2300 - val_loss: 3.8528 - val_acc: 0.1074 - val_top5-acc: 0.3228 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 3.7183 - acc: 0.1286 - top5-acc: 0.3526 - val_loss: 3.5733 - val_acc: 0.1564 - val_top5-acc: 0.3988 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 3.4625 - acc: 0.1714 - top5-acc: 0.4285 - val_loss: 3.2876 - val_acc: 0.2050 - val_top5-acc: 0.4762 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 39s 111ms/step - loss: 3.2690 - acc: 0.2056 - top5-acc: 0.4838 - val_loss: 3.1228 - val_acc: 0.2364 - val_top5-acc: 0.5124 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 3.1324 - acc: 0.2296 - top5-acc: 0.5207 - val_loss: 3.0093 - val_acc: 0.2500 - val_top5-acc: 0.5512 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 3.0071 - acc: 0.2528 - top5-acc: 0.5505 - val_loss: 2.9359 - val_acc: 0.2632 - val_top5-acc: 0.5688 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "352/352 [==============================] - 37s 106ms/step - loss: 2.9096 - acc: 0.2700 - top5-acc: 0.5756 - val_loss: 2.8200 - val_acc: 0.2824 - val_top5-acc: 0.5922 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.8332 - acc: 0.2866 - top5-acc: 0.5922 - val_loss: 2.7833 - val_acc: 0.2976 - val_top5-acc: 0.6044 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.7607 - acc: 0.3015 - top5-acc: 0.6129 - val_loss: 2.7017 - val_acc: 0.3158 - val_top5-acc: 0.6272 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "352/352 [==============================] - 39s 110ms/step - loss: 2.6954 - acc: 0.3156 - top5-acc: 0.6295 - val_loss: 2.6299 - val_acc: 0.3278 - val_top5-acc: 0.6460 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "352/352 [==============================] - 38s 109ms/step - loss: 2.6471 - acc: 0.3220 - top5-acc: 0.6385 - val_loss: 2.5716 - val_acc: 0.3442 - val_top5-acc: 0.6548 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.5813 - acc: 0.3372 - top5-acc: 0.6534 - val_loss: 2.5682 - val_acc: 0.3428 - val_top5-acc: 0.6534 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.5372 - acc: 0.3452 - top5-acc: 0.6634 - val_loss: 2.5451 - val_acc: 0.3412 - val_top5-acc: 0.6598 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.5044 - acc: 0.3528 - top5-acc: 0.6713 - val_loss: 2.4946 - val_acc: 0.3506 - val_top5-acc: 0.6772 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.4548 - acc: 0.3626 - top5-acc: 0.6836 - val_loss: 2.4585 - val_acc: 0.3686 - val_top5-acc: 0.6792 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.4168 - acc: 0.3708 - top5-acc: 0.6905 - val_loss: 2.4372 - val_acc: 0.3696 - val_top5-acc: 0.6802 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "352/352 [==============================] - 39s 110ms/step - loss: 2.3857 - acc: 0.3778 - top5-acc: 0.6973 - val_loss: 2.3773 - val_acc: 0.3888 - val_top5-acc: 0.6996 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.3571 - acc: 0.3842 - top5-acc: 0.7042 - val_loss: 2.3612 - val_acc: 0.3944 - val_top5-acc: 0.6992 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.3328 - acc: 0.3878 - top5-acc: 0.7107 - val_loss: 2.4121 - val_acc: 0.3706 - val_top5-acc: 0.6880 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.2993 - acc: 0.3962 - top5-acc: 0.7150 - val_loss: 2.3217 - val_acc: 0.4036 - val_top5-acc: 0.7016 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.2704 - acc: 0.4047 - top5-acc: 0.7244 - val_loss: 2.3253 - val_acc: 0.3990 - val_top5-acc: 0.7056 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.2453 - acc: 0.4090 - top5-acc: 0.7271 - val_loss: 2.2855 - val_acc: 0.4040 - val_top5-acc: 0.7154 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "352/352 [==============================] - 38s 109ms/step - loss: 2.2266 - acc: 0.4159 - top5-acc: 0.7289 - val_loss: 2.3102 - val_acc: 0.3988 - val_top5-acc: 0.7102 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.2065 - acc: 0.4156 - top5-acc: 0.7348 - val_loss: 2.2669 - val_acc: 0.4042 - val_top5-acc: 0.7224 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.1864 - acc: 0.4184 - top5-acc: 0.7345 - val_loss: 2.2592 - val_acc: 0.4082 - val_top5-acc: 0.7178 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 2.1665 - acc: 0.4236 - top5-acc: 0.7426 - val_loss: 2.2541 - val_acc: 0.4184 - val_top5-acc: 0.7210 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.1540 - acc: 0.4263 - top5-acc: 0.7442 - val_loss: 2.2940 - val_acc: 0.4036 - val_top5-acc: 0.7202 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.1372 - acc: 0.4306 - top5-acc: 0.7477 - val_loss: 2.2863 - val_acc: 0.4058 - val_top5-acc: 0.7190 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.1146 - acc: 0.4363 - top5-acc: 0.7520 - val_loss: 2.2289 - val_acc: 0.4206 - val_top5-acc: 0.7258 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "352/352 [==============================] - 38s 109ms/step - loss: 2.1013 - acc: 0.4398 - top5-acc: 0.7549 - val_loss: 2.2547 - val_acc: 0.4194 - val_top5-acc: 0.7254 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.0923 - acc: 0.4401 - top5-acc: 0.7581 - val_loss: 2.2561 - val_acc: 0.4126 - val_top5-acc: 0.7208 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "352/352 [==============================] - 39s 109ms/step - loss: 2.0811 - acc: 0.4438 - top5-acc: 0.7620 - val_loss: 2.2051 - val_acc: 0.4124 - val_top5-acc: 0.7352 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.0631 - acc: 0.4456 - top5-acc: 0.7635 - val_loss: 2.1918 - val_acc: 0.4242 - val_top5-acc: 0.7310 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "352/352 [==============================] - 38s 109ms/step - loss: 2.0509 - acc: 0.4488 - top5-acc: 0.7661 - val_loss: 2.2021 - val_acc: 0.4184 - val_top5-acc: 0.7318 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.0495 - acc: 0.4506 - top5-acc: 0.7654 - val_loss: 2.2114 - val_acc: 0.4210 - val_top5-acc: 0.7274 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "352/352 [==============================] - 39s 111ms/step - loss: 2.0286 - acc: 0.4548 - top5-acc: 0.7693 - val_loss: 2.1977 - val_acc: 0.4316 - val_top5-acc: 0.7368 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.0239 - acc: 0.4550 - top5-acc: 0.7711 - val_loss: 2.1971 - val_acc: 0.4246 - val_top5-acc: 0.7322 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "352/352 [==============================] - 38s 108ms/step - loss: 2.0118 - acc: 0.4590 - top5-acc: 0.7740 - val_loss: 2.1836 - val_acc: 0.4268 - val_top5-acc: 0.7372 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.9950 - acc: 0.4687 - top5-acc: 0.7749 - val_loss: 2.1949 - val_acc: 0.4286 - val_top5-acc: 0.7392 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "352/352 [==============================] - 38s 109ms/step - loss: 1.9869 - acc: 0.4642 - top5-acc: 0.7788 - val_loss: 2.1983 - val_acc: 0.4352 - val_top5-acc: 0.7344 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.9874 - acc: 0.4662 - top5-acc: 0.7790 - val_loss: 2.1414 - val_acc: 0.4446 - val_top5-acc: 0.7472 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "352/352 [==============================] - 39s 111ms/step - loss: 1.9715 - acc: 0.4698 - top5-acc: 0.7784 - val_loss: 2.1758 - val_acc: 0.4278 - val_top5-acc: 0.7382 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.9591 - acc: 0.4686 - top5-acc: 0.7848 - val_loss: 2.1657 - val_acc: 0.4354 - val_top5-acc: 0.7404 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "352/352 [==============================] - 38s 109ms/step - loss: 1.9568 - acc: 0.4691 - top5-acc: 0.7852 - val_loss: 2.1267 - val_acc: 0.4400 - val_top5-acc: 0.7510 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.9405 - acc: 0.4743 - top5-acc: 0.7890 - val_loss: 2.1462 - val_acc: 0.4464 - val_top5-acc: 0.7448 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.9386 - acc: 0.4740 - top5-acc: 0.7876 - val_loss: 2.1797 - val_acc: 0.4380 - val_top5-acc: 0.7376 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.9274 - acc: 0.4763 - top5-acc: 0.7887 - val_loss: 2.1457 - val_acc: 0.4362 - val_top5-acc: 0.7534 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "352/352 [==============================] - 38s 109ms/step - loss: 1.9193 - acc: 0.4817 - top5-acc: 0.7918 - val_loss: 2.1524 - val_acc: 0.4402 - val_top5-acc: 0.7476 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.9166 - acc: 0.4787 - top5-acc: 0.7919 - val_loss: 2.1295 - val_acc: 0.4470 - val_top5-acc: 0.7460 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "352/352 [==============================] - 38s 107ms/step - loss: 1.7736 - acc: 0.5148 - top5-acc: 0.8166 - val_loss: 2.0525 - val_acc: 0.4620 - val_top5-acc: 0.7632 - lr: 5.0000e-04\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.0096 - acc: 0.4744 - top5-acc: 0.7696\n",
            "Test accuracy: 47.44%\n",
            "Test top 5 accuracy: 76.96%\n"
          ]
        }
      ],
      "source": [
        "fnet_blocks = keras.Sequential(\n",
        "    [FNetLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n",
        ")\n",
        "learning_rate = 0.001\n",
        "fnet_classifier = build_classifier(fnet_blocks, positional_encoding=True)\n",
        "history = run_experiment(fnet_classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc601f95",
      "metadata": {
        "id": "cc601f95"
      },
      "source": [
        "## The gMlp model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c05076ea",
      "metadata": {
        "id": "c05076ea"
      },
      "source": [
        "### Implement the gMLP module"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The gMLP is a MLP architecture that features a Spatial Gating Unit (SGU). The SGU enables cross-patch interactions across the spatial (channel) dimension, by:\n",
        "\n",
        "Transforming the input spatially by applying linear projection across patches (along channels).\n",
        "Applying element-wise multiplication of the input and its spatial transformation."
      ],
      "metadata": {
        "id": "xNCw-5eEay7L"
      },
      "id": "xNCw-5eEay7L"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1bbd29fe",
      "metadata": {
        "id": "1bbd29fe"
      },
      "outputs": [],
      "source": [
        "class gMLPLayer(layers.Layer):\n",
        "    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n",
        "        super(gMLPLayer, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.channel_projection1 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=embedding_dim * 2),\n",
        "                tfa.layers.GELU(),\n",
        "                layers.Dropout(rate=dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.channel_projection2 = layers.Dense(units=embedding_dim)\n",
        "\n",
        "        self.spatial_projection = layers.Dense(\n",
        "            units=num_patches, bias_initializer=\"Ones\"\n",
        "        )\n",
        "\n",
        "        self.normalize1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.normalize2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def spatial_gating_unit(self, x):\n",
        "        # Split x along the channel dimensions.\n",
        "        # Tensors u and v will in th shape of [batch_size, num_patchs, embedding_dim].\n",
        "        u, v = tf.split(x, num_or_size_splits=2, axis=2)\n",
        "        # Apply layer normalization.\n",
        "        v = self.normalize2(v)\n",
        "        # Apply spatial projection.\n",
        "        v_channels = tf.linalg.matrix_transpose(v)\n",
        "        v_projected = self.spatial_projection(v_channels)\n",
        "        v_projected = tf.linalg.matrix_transpose(v_projected)\n",
        "        # Apply element-wise multiplication.\n",
        "        return u * v_projected\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply layer normalization.\n",
        "        x = self.normalize1(inputs)\n",
        "        # Apply the first channel projection. x_projected shape: [batch_size, num_patches, embedding_dim * 2].\n",
        "        x_projected = self.channel_projection1(x)\n",
        "        # Apply the spatial gating unit. x_spatial shape: [batch_size, num_patches, embedding_dim].\n",
        "        x_spatial = self.spatial_gating_unit(x_projected)\n",
        "        # Apply the second channel projection. x_projected shape: [batch_size, num_patches, embedding_dim].\n",
        "        x_projected = self.channel_projection2(x_spatial)\n",
        "        # Add skip connection.\n",
        "        return x + x_projected"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0f15a10",
      "metadata": {
        "id": "a0f15a10"
      },
      "source": [
        "### Build, train, and evaluate the gMLP model\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0bf148a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bf148a1",
        "outputId": "94ac2335-0bd9-4872-b53d-375c12e4a6ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "352/352 [==============================] - 46s 119ms/step - loss: 3.9187 - acc: 0.0963 - top5-acc: 0.2968 - val_loss: 3.5686 - val_acc: 0.1492 - val_top5-acc: 0.4146 - lr: 0.0030\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 42s 120ms/step - loss: 3.4666 - acc: 0.1659 - top5-acc: 0.4321 - val_loss: 3.3076 - val_acc: 0.1924 - val_top5-acc: 0.4740 - lr: 0.0030\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 41s 117ms/step - loss: 3.2458 - acc: 0.2078 - top5-acc: 0.4901 - val_loss: 3.1329 - val_acc: 0.2340 - val_top5-acc: 0.5266 - lr: 0.0030\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 41s 117ms/step - loss: 3.0660 - acc: 0.2410 - top5-acc: 0.5376 - val_loss: 2.9265 - val_acc: 0.2714 - val_top5-acc: 0.5716 - lr: 0.0030\n",
            "Epoch 5/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 2.9380 - acc: 0.2639 - top5-acc: 0.5687 - val_loss: 2.8291 - val_acc: 0.2886 - val_top5-acc: 0.6008 - lr: 0.0030\n",
            "Epoch 6/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 2.8312 - acc: 0.2882 - top5-acc: 0.5970 - val_loss: 2.8253 - val_acc: 0.2970 - val_top5-acc: 0.6030 - lr: 0.0030\n",
            "Epoch 7/50\n",
            "352/352 [==============================] - 42s 120ms/step - loss: 2.7396 - acc: 0.3066 - top5-acc: 0.6187 - val_loss: 2.7365 - val_acc: 0.3170 - val_top5-acc: 0.6264 - lr: 0.0030\n",
            "Epoch 8/50\n",
            "352/352 [==============================] - 45s 127ms/step - loss: 2.6755 - acc: 0.3171 - top5-acc: 0.6343 - val_loss: 2.6216 - val_acc: 0.3380 - val_top5-acc: 0.6420 - lr: 0.0030\n",
            "Epoch 9/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 2.6267 - acc: 0.3288 - top5-acc: 0.6453 - val_loss: 2.5742 - val_acc: 0.3440 - val_top5-acc: 0.6568 - lr: 0.0030\n",
            "Epoch 10/50\n",
            "352/352 [==============================] - 41s 117ms/step - loss: 2.5774 - acc: 0.3399 - top5-acc: 0.6554 - val_loss: 2.5477 - val_acc: 0.3452 - val_top5-acc: 0.6632 - lr: 0.0030\n",
            "Epoch 11/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 2.5243 - acc: 0.3478 - top5-acc: 0.6676 - val_loss: 2.5381 - val_acc: 0.3536 - val_top5-acc: 0.6678 - lr: 0.0030\n",
            "Epoch 12/50\n",
            "352/352 [==============================] - 41s 117ms/step - loss: 2.4601 - acc: 0.3626 - top5-acc: 0.6788 - val_loss: 2.4238 - val_acc: 0.3744 - val_top5-acc: 0.6932 - lr: 0.0030\n",
            "Epoch 13/50\n",
            "352/352 [==============================] - 42s 119ms/step - loss: 2.3780 - acc: 0.3810 - top5-acc: 0.6982 - val_loss: 2.4130 - val_acc: 0.3852 - val_top5-acc: 0.6994 - lr: 0.0030\n",
            "Epoch 14/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 2.3419 - acc: 0.3858 - top5-acc: 0.7062 - val_loss: 2.4138 - val_acc: 0.3892 - val_top5-acc: 0.6922 - lr: 0.0030\n",
            "Epoch 15/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 2.3025 - acc: 0.3959 - top5-acc: 0.7127 - val_loss: 2.3747 - val_acc: 0.3942 - val_top5-acc: 0.7018 - lr: 0.0030\n",
            "Epoch 16/50\n",
            "352/352 [==============================] - 41s 118ms/step - loss: 2.2781 - acc: 0.4013 - top5-acc: 0.7183 - val_loss: 2.3731 - val_acc: 0.3984 - val_top5-acc: 0.6996 - lr: 0.0030\n",
            "Epoch 17/50\n",
            "352/352 [==============================] - 41s 115ms/step - loss: 2.2483 - acc: 0.4086 - top5-acc: 0.7250 - val_loss: 2.3238 - val_acc: 0.4080 - val_top5-acc: 0.7166 - lr: 0.0030\n",
            "Epoch 18/50\n",
            "352/352 [==============================] - 42s 120ms/step - loss: 2.2197 - acc: 0.4118 - top5-acc: 0.7325 - val_loss: 2.3707 - val_acc: 0.4042 - val_top5-acc: 0.7076 - lr: 0.0030\n",
            "Epoch 19/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 2.1950 - acc: 0.4205 - top5-acc: 0.7353 - val_loss: 2.3125 - val_acc: 0.4186 - val_top5-acc: 0.7182 - lr: 0.0030\n",
            "Epoch 20/50\n",
            "352/352 [==============================] - 41s 117ms/step - loss: 2.1720 - acc: 0.4240 - top5-acc: 0.7414 - val_loss: 2.3391 - val_acc: 0.4100 - val_top5-acc: 0.7118 - lr: 0.0030\n",
            "Epoch 21/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 2.1464 - acc: 0.4291 - top5-acc: 0.7456 - val_loss: 2.3020 - val_acc: 0.4184 - val_top5-acc: 0.7190 - lr: 0.0030\n",
            "Epoch 22/50\n",
            "352/352 [==============================] - 42s 118ms/step - loss: 2.1262 - acc: 0.4345 - top5-acc: 0.7491 - val_loss: 2.2544 - val_acc: 0.4236 - val_top5-acc: 0.7364 - lr: 0.0030\n",
            "Epoch 23/50\n",
            "352/352 [==============================] - 42s 118ms/step - loss: 2.1063 - acc: 0.4380 - top5-acc: 0.7540 - val_loss: 2.2715 - val_acc: 0.4248 - val_top5-acc: 0.7278 - lr: 0.0030\n",
            "Epoch 24/50\n",
            "352/352 [==============================] - 42s 120ms/step - loss: 2.0839 - acc: 0.4446 - top5-acc: 0.7586 - val_loss: 2.2581 - val_acc: 0.4226 - val_top5-acc: 0.7308 - lr: 0.0030\n",
            "Epoch 25/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 2.0668 - acc: 0.4479 - top5-acc: 0.7622 - val_loss: 2.2986 - val_acc: 0.4240 - val_top5-acc: 0.7238 - lr: 0.0030\n",
            "Epoch 26/50\n",
            "352/352 [==============================] - 41s 117ms/step - loss: 2.0440 - acc: 0.4522 - top5-acc: 0.7657 - val_loss: 2.2755 - val_acc: 0.4222 - val_top5-acc: 0.7274 - lr: 0.0030\n",
            "Epoch 27/50\n",
            "352/352 [==============================] - 41s 117ms/step - loss: 2.0223 - acc: 0.4581 - top5-acc: 0.7706 - val_loss: 2.2369 - val_acc: 0.4250 - val_top5-acc: 0.7366 - lr: 0.0030\n",
            "Epoch 28/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 2.0149 - acc: 0.4579 - top5-acc: 0.7730 - val_loss: 2.2135 - val_acc: 0.4374 - val_top5-acc: 0.7400 - lr: 0.0030\n",
            "Epoch 29/50\n",
            "352/352 [==============================] - 42s 120ms/step - loss: 1.9944 - acc: 0.4609 - top5-acc: 0.7777 - val_loss: 2.2660 - val_acc: 0.4326 - val_top5-acc: 0.7410 - lr: 0.0030\n",
            "Epoch 30/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.9835 - acc: 0.4624 - top5-acc: 0.7791 - val_loss: 2.2237 - val_acc: 0.4384 - val_top5-acc: 0.7406 - lr: 0.0030\n",
            "Epoch 31/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.9701 - acc: 0.4679 - top5-acc: 0.7828 - val_loss: 2.2292 - val_acc: 0.4404 - val_top5-acc: 0.7386 - lr: 0.0030\n",
            "Epoch 32/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.9528 - acc: 0.4726 - top5-acc: 0.7833 - val_loss: 2.2212 - val_acc: 0.4442 - val_top5-acc: 0.7440 - lr: 0.0030\n",
            "Epoch 33/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.9383 - acc: 0.4741 - top5-acc: 0.7867 - val_loss: 2.2950 - val_acc: 0.4288 - val_top5-acc: 0.7374 - lr: 0.0030\n",
            "Epoch 34/50\n",
            "352/352 [==============================] - 42s 118ms/step - loss: 1.7514 - acc: 0.5181 - top5-acc: 0.8207 - val_loss: 2.1205 - val_acc: 0.4718 - val_top5-acc: 0.7668 - lr: 0.0015\n",
            "Epoch 35/50\n",
            "352/352 [==============================] - 42s 120ms/step - loss: 1.7017 - acc: 0.5300 - top5-acc: 0.8282 - val_loss: 2.1554 - val_acc: 0.4606 - val_top5-acc: 0.7592 - lr: 0.0015\n",
            "Epoch 36/50\n",
            "352/352 [==============================] - 41s 117ms/step - loss: 1.6829 - acc: 0.5342 - top5-acc: 0.8318 - val_loss: 2.1324 - val_acc: 0.4724 - val_top5-acc: 0.7660 - lr: 0.0015\n",
            "Epoch 37/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.6688 - acc: 0.5349 - top5-acc: 0.8337 - val_loss: 2.1455 - val_acc: 0.4668 - val_top5-acc: 0.7610 - lr: 0.0015\n",
            "Epoch 38/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.6523 - acc: 0.5413 - top5-acc: 0.8370 - val_loss: 2.1466 - val_acc: 0.4744 - val_top5-acc: 0.7628 - lr: 0.0015\n",
            "Epoch 39/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.6352 - acc: 0.5436 - top5-acc: 0.8400 - val_loss: 2.1597 - val_acc: 0.4712 - val_top5-acc: 0.7594 - lr: 0.0015\n",
            "Epoch 40/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.5091 - acc: 0.5757 - top5-acc: 0.8618 - val_loss: 2.1185 - val_acc: 0.4848 - val_top5-acc: 0.7726 - lr: 7.5000e-04\n",
            "Epoch 41/50\n",
            "352/352 [==============================] - 42s 119ms/step - loss: 1.4629 - acc: 0.5857 - top5-acc: 0.8690 - val_loss: 2.1227 - val_acc: 0.4888 - val_top5-acc: 0.7714 - lr: 7.5000e-04\n",
            "Epoch 42/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.4499 - acc: 0.5897 - top5-acc: 0.8711 - val_loss: 2.1355 - val_acc: 0.4824 - val_top5-acc: 0.7734 - lr: 7.5000e-04\n",
            "Epoch 43/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.4402 - acc: 0.5903 - top5-acc: 0.8717 - val_loss: 2.1289 - val_acc: 0.4814 - val_top5-acc: 0.7764 - lr: 7.5000e-04\n",
            "Epoch 44/50\n",
            "352/352 [==============================] - 41s 117ms/step - loss: 1.4325 - acc: 0.5929 - top5-acc: 0.8737 - val_loss: 2.1670 - val_acc: 0.4798 - val_top5-acc: 0.7678 - lr: 7.5000e-04\n",
            "Epoch 45/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.4227 - acc: 0.5960 - top5-acc: 0.8753 - val_loss: 2.1402 - val_acc: 0.4834 - val_top5-acc: 0.7738 - lr: 7.5000e-04\n",
            "Epoch 46/50\n",
            "352/352 [==============================] - 42s 120ms/step - loss: 1.3387 - acc: 0.6178 - top5-acc: 0.8884 - val_loss: 2.1388 - val_acc: 0.4834 - val_top5-acc: 0.7758 - lr: 3.7500e-04\n",
            "Epoch 47/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.3204 - acc: 0.6208 - top5-acc: 0.8920 - val_loss: 2.1220 - val_acc: 0.4836 - val_top5-acc: 0.7782 - lr: 3.7500e-04\n",
            "Epoch 48/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.3149 - acc: 0.6240 - top5-acc: 0.8926 - val_loss: 2.1135 - val_acc: 0.4888 - val_top5-acc: 0.7774 - lr: 3.7500e-04\n",
            "Epoch 49/50\n",
            "352/352 [==============================] - 41s 116ms/step - loss: 1.3132 - acc: 0.6257 - top5-acc: 0.8925 - val_loss: 2.1241 - val_acc: 0.4896 - val_top5-acc: 0.7762 - lr: 3.7500e-04\n",
            "Epoch 50/50\n",
            "352/352 [==============================] - 41s 117ms/step - loss: 1.3037 - acc: 0.6277 - top5-acc: 0.8953 - val_loss: 2.1237 - val_acc: 0.4872 - val_top5-acc: 0.7754 - lr: 3.7500e-04\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 2.0806 - acc: 0.4952 - top5-acc: 0.7765\n",
            "Test accuracy: 49.52%\n",
            "Test top 5 accuracy: 77.65%\n"
          ]
        }
      ],
      "source": [
        "gmlp_blocks = keras.Sequential(\n",
        "    [gMLPLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n",
        ")\n",
        "learning_rate = 0.003\n",
        "gmlp_classifier = build_classifier(gmlp_blocks)\n",
        "history = run_experiment(gmlp_classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "We can concluse that to get the better results for the three models (the MLP-Mixer, the FNet ,the gML ) we  can be achieved by increasing the embedding dimensions, increasing the number of (gMlp , FNet , mixer) blocks, and training the model for longer. You may also try to increase the size of the input images and use different patch sizes."
      ],
      "metadata": {
        "id": "XSHkFXlFZtDb"
      },
      "id": "XSHkFXlFZtDb"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}